---
  title: "R Notebook"
  output: Final Exam
---
  
  Below are the three questions for the PBIO 294 Final Exam.  All work must be your own.  Reference to outside sources should be limited to the documentation for R, Stan, JAGS, or general questions regarding pdf's, etc.  This exam is due by midnight, Monday, 11 Dec 2017. 20% will be deducted for each additonal 6 hours that this exam is turned in late. Please email your R/.Rmd file to brian.beckage@uvm.edu.


1. (30 points) An ecologist is interested in the intermediate disturbance hypothesis (IDH) 
that postulates that the highest species richness should be found at intermediate levels of 
disturbance. Write a  likelihood function to estimate the  
parameters for a quadratic regression models given in Beckage and Stout 2000 
(http://www.uvm.edu/~bbeckage/Manuscripts/BeckageStout.corrected.2000.jvs.pdf), 
but assuming a Poisson likelihood with a log link function.  Provide your i. *likelihood function and supporting R code for finding the MLE's*, ii. a *plot of the data with the fitted line* and iii. report the *regression parameters (bo, b1, and b2)*, and iv. the value of the *negative log likelihood at the MLEs*.  Note:  You must write your own likelihood function and not use a built in R function or package, e.g, lm, glm, etc.

The data may be read using:
  ```{r}
srDat <- read.table("http://www.uvm.edu/~bbeckage/Teaching/PBIO_294/Data/idh.csv", sep = ',', header = TRUE)
```

### i. Fit the Poisson regression using maximum likelihood.

## Negative-log likelihood function
```{r}
nllPois <- function(par, data) {
  b0 <- par[1]
  b1 <- par[2]
  b2 <- par[3]
  burnPred <- exp(b0 + b1 * data$nFires + b2 * (data$nFires^2))
  nllik <- -sum(dpois(x = data$sr, lambda = burnPred, log = TRUE))
  # cat("nllik= ",nllik,sep=" ",fill=T);cat(" ",sep=" ",fill=T)
  return(nllik)
}
```

## MLE optimization
```{r}
beta0 <- 1.0; beta1 <- 1.0; beta2 <- 0
par <- c(beta0, beta1, beta2)
outPois <- optim(par = par, fn = nllPois, data = srDat)

## regression parameters (bo, b1, and b2)
outPois$par # 2.05978733, 0.44236140, and -0.04571526

## negative log likelihood value
outPois$val # 848.0102 

## AIC value
myAIC <- 2 * 3 + 2 * outPois$val # 1702.02
```
\hfill  

## Plot of the data with the fitted line  
```{r}
burnPred <- order(srDat$nFires)
plot(sr~nFires, data = srDat)
lines(burnPred, exp(outPois$par[1]+outPois$par[2]*burnPred+outPois$par[3]*(burnPred^2)),col='red',lwd=2)
```


##############################################################################################################


2. (30 points) Repeat exercise 1 except now fitting the model using either Rstan or Rjags.  You must write your own Stan/JAGS model, meaning that you can not use one of the Stan helper libraries such as the brms or rstanarm libraries. Provide your i. *Stan/JAGS model code and supporting R code for running the Stan/JAGS model*, ii. report the *2.5%, 50%, and 97.5% percentiles for the regression parameters (bo, b1, and b2)*, iii. *plot the posterior distributions for each of these parameters* and iv. *assess the convergence of your chains using the Gelman-Rubin statistic.* 
  
  ```{r}
library(rjags)

jags.data <- list(n = length(srDat$sr), sr = srDat$sr, burns = srDat$nFires)

## model written in the JAGS
cat("
    model
    {
    # priors
    beta0 ~ dnorm(0,0.001)
    beta1 ~ dnorm(0,0.001)
    beta2 ~ dnorm(0,0.001)
    
    # likelihood
    for(i in 1:n)
    {
    sr[i] ~ dpois(lambda[i])
    log(lambda[i]) <- beta0 + beta1*burns[i] + beta2*pow(burns[i],2)
    # this part is here in order to make nice prediction curves:
    prediction[i] ~ dpois(lambda[i])
    } 
    }
    ", file="model.txt")

## specify the parameters that will be monitored during the MCMC sampling
params <- c("beta0", "beta1", "beta2", "prediction")

jm <- jags.model("model.txt", data = jags.data, n.chains = 3, n.adapt = 25000)
update(jm, n.iter = 5000)
jm.sample <- jags.samples(jm, variable.names = params, n.iter = 10000, thin = 1)


## 2.5%, 50%, and 97.5% percentiles for the regression parameters (bo, b1, and b2)
summary(as.mcmc.list(jm.sample$beta0))  # 1.949, 2.070, and 2.190
summary(as.mcmc.list(jm.sample$beta1))  # 0.3867, 0.4370, and 0.4869
summary(as.mcmc.list(jm.sample$beta2))  # -0.04976, -0.04521, and -0.04059


## plot the posterior distributions for each of these parameters
plot(as.mcmc.list(jm.sample$beta0), main = "Beta_0")
plot(as.mcmc.list(jm.sample$beta1), main = "Beta_1")
plot(as.mcmc.list(jm.sample$beta2), main = "Beta_2")

## assess the convergence of your chains using the Gelman-Rubin statistic
gelman.diag(as.mcmc.list(jm.sample$beta0))
gelman.diag(as.mcmc.list(jm.sample$beta1))
gelman.diag(as.mcmc.list(jm.sample$beta2))

## A rule of thumb is that values of 1.1 and less suggests adequate convergence, so we accept that convergence was achieved.
```



3. (40 points) An ecologist expects seed predation to be influenced by the presence of openings (gaps) in the forest overstory and seed mass. The effect of seed mass on predation is expected be quadratic:  Small seeds will be less predated because they offer a lower energetic reward while larger seeds will be too difficult to process, so that medium sized seeds will be most predated.  The effect of a gap is additive with lower predation expected in gaps because seed predators avoid areas of open canopy. The ecologist models the data as a hierarchical logistic regression, assuming that the seed masses are known without observation error.  The model has the form:
  
  Seed lost ~ Binomial(theta) # 1 if seed is predated, 0 if seed is left alone
Logit(theta) = b0i + b1 x gap 
b0i ~ gamma(mu^2/sd^2,mu/sd^2) 
mui = b2 + b3 x seed mass i - b4 x (seed mass i)^2 
sd^2 ~ gamma(0.001,0.001)
b1,b2,b3,b4 ~ normal(0,100)

Fit this model using either Rstan or Rjags.  You must write your own Stan/JAGS model, meaning that you can not use one of the Stan helper libraries such as the brms or rstanarm libraries. Provide your i. *Stan/JAGS model code and supporting R code for running the Stan/JAGS model*, ii. report the *2.5%, 50%, and 97.5% percentiles for the regression parameters (b1, b1, b2, b3, and b4)*, iii. *plot the posterior distributions for each of these parameters* and iv. *assess the convergence of your chains using the Gelman-Rubin statistic.*
  
  The data can be read using:
  ```{r}
library(dplyr)
library(rstan)
seeds <- read.table("http://www.uvm.edu/~bbeckage/Teaching/PBIO_294/Data/seeds.csv", sep = ',', header = TRUE) %>% 
  mutate(mass.sq = mass^2) %>% 
  select(seedLost, gap, mass, mass.sq)
```


```{r}
seed_code <- '
data {
int N; // number of obs (seeds)
int K; // number of predictors (gap, mass, mass^2)

int y[N]; // outcome
row_vector[K] x[N]; // predictors
}
parameters {
real beta0;
vector[K] beta;
real<lower=0,upper=10> sigma;  
}
model {
beta0 ~ normal(0,100);
beta ~ normal(0,100);
for(n in 1:N) {
y[n] ~ bernoulli(inv_logit(beta0 + x[n]*beta));
}
}
'

## Create data list
seed_data <- list(N = nrow(seeds), K = 3, y = seeds[,1], x = seeds[,2:4])

## Run stan model
hfit <- stan(model_code = seed_code, data = seed_data, iter = 10000, chains = 4)

# Note: I do not understand why the question asks for 4 parameter estimates when there are only 3 predictor   variables. This was what I wanted to discuss when I emailed you about meeting. It was not clear what the grouping variable is also. What variable is nested?

## 2.5%, 50%, and 97.5% percentiles for the regression parameters (b0, b1, b2, and b3) and the Gelman-Rubin statistic
print(hfit, pars = c("beta0", "beta[1]", "beta[2]", "beta[3]"), probs = c(0.025, 0.50, 0.975), digits_summary = 3)

# beta0: -0.635; 1.0
# beta1: 2.488; 1.0
# beta2: 0.191; 1.0
# beta3: 0.005; 1.0

## plot the posterior distributions for each parameter
rstan::traceplot(hfit, c("beta0", "beta[1]", "beta[2]", "beta[3]"),
                 ncol = 1, nrow = 5, inc_warmup = F)
```
