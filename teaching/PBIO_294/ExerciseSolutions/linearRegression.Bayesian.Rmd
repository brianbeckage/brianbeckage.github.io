---
title: "Bayesian Linear Regression"
output: html_document
---
We fit a linear regression model to the !Kung data within the Rethinking package
using 6 methods. 1) R's builtin lm(), 2) likelihood function, 3) Rethinking quap, 
4) Rethinking ulam, 5) Nimble, and 6) Rstan/Stan.


This exercise uses the !Kung height vs. weight data from the Rethinking package for adults age 18 or older.

Load and examine the data.
```{r}
library(rethinking)
data(Howell1)
d <- Howell1
d2 <- d[ d$age >= 18 , ]
head(d2)
plot(height~weight, data=d2)

# Scaling the predictor variable weight and the response varible height
# both to mean = 0, sd = 1.
d3<-d4<-d2
d3[,'weight']<-scale(d3[,'weight'])
d3[,'height']<-scale(d3[,'height'])

### Standardizing only the predictor weight
###  I would probably not standardize the response variable height
d4[,'weight']<-scale(d4[,'weight'])

```


1) Fit a linear regression to these data using the ‘lm’ command within R. The model should predict the observed weight from height and the model should include an intercept and an effect of height. Plot the estimated linear fit superimposed on the data and report the parameter estimates for the intercept, effect of height, and sigma.

```{r}

out<-lm(height~weight,data=d2)
summary(out,correlation=TRUE) # # correlation about -0.99

# Repeating but with scaled columns
out2<-lm(height~weight,data=d3)
summary(out2,correlation=TRUE) # correlation now 0

plot(height~weight, data=d3)
abline(a=out2$coefficients[1],b=out2$coefficients[2])
library(stats)
sigma(out2)
```


2) We fit the linear model using our own likelihood function rather than R’s built in ‘lm’. Plot the estimated linear fit superimposed on the data and report the parameter estimates for the intercept, effect of height, and sigma. Are they the same as from ‘lm’?

Here is our likelihood function.  We actually work with the negative log likelihood.
Why?

```{r}
nllNormReg<-function(parVec,data=d3){
  wt<-data$weight
  ht<-data$height
  intercept<-parVec[1]
  beta<-parVec[2]
  mySd<-parVec[3]
  htPred<-intercept+beta*wt
  nllik<- -sum(dnorm(x=ht,mean=htPred,sd=mySd,log=TRUE))
  #browser()
  return(nllik)
}
```

Minimizing the negative log likelihood function above.  This is equivalent to finding the maximum likelihood estimate.
```{r}

parVec<-c(1.0,2.0,2.0) # Need some starting parameters for gradient climbing/descending methods
outLM<-optim(par=parVec,fn=nllNormReg,method="L-BFGS-B",
               lower=c(-Inf,-Inf,0.0001),upper=c(Inf,Inf,Inf))
outLM$par # 


```
From R's lm above:
intercept = 5.794e-17 (~ 0)
weight = 7.547e-01
sigma = 0.6569515



3) We fit the linear model using the quap in the Rethinking package. Report the parameter estimates for the intercept, effect of height, and sigma. Are they the same as from ‘lm’? The quap function uses a normal approximation of posterior.
```{r}
library(rethinking)

modelQUAP <- quap(
    alist(
        height ~ dnorm( mu , sigma ) ,
        mu <- intercept + beta*weight ,
        intercept ~ dnorm( 10 , 20 ) ,
        beta ~ dnorm( 0 , 5 ) ,
        sigma ~ dunif( 0 , 50 )
    ) , data=d3 )

precis( modelQUAP )

```
From R's lm above:
intercept = 5.794e-17 (~ 0)
weight = 7.547e-01
sigma = 0.6569515



4) We fit the linear model using the ulam function in the Rethinking package. Report the parameter estimates for the intercept, effect of height, and sigma. Are they the same as from ‘lm’? The ulam function uses MCMC sampling to estimate the posterior.

```{r}
library(rethinking)

modelMCMC <- ulam(
      alist(
        height ~ dnorm( mu , sigma ) ,
        mu <- intercept + beta*weight ,
        intercept ~ dnorm( 178 , 20 ) ,
        beta ~ dnorm( 0 , 1 ) ,
        sigma ~ dunif( 0 , 50 )
      )
   , data=list(height=d3$height, weight=d3$weight) , chains=3 )

precis(modelMCMC)
```
From R's lm above:
intercept = 5.794e-17 (~ 0)
weight = 7.547e-01
sigma = 0.6569515


5) We fit the linear model using the Nimble package in R. Report the parameter estimates for the intercept, effect of height, and sigma. Are they the same as from ‘lm’? 

```{r}
library(nimble)

myCode <- nimbleCode({
  intercept ~ dnorm(0, sd = 10)
  beta ~ dnorm(0, sd = 10)
  sigma ~ dunif(0, 50)  # prior for variance components based on Gelman (2006)
  for(i in 1:n) {
    mu[i]<-intercept + beta*weight[i]
    height[i] ~ dnorm(mu[i], sd = sigma) 
  }
})

myConstants <- list(n = dim(d2)[1], weight = d2$weight)
myData <- list(height = d2$height)
myInits <- list(intercept = mean(d3$height), beta = 0, sigma = sqrt(var(d2$height)))
```


```{r}
mcmc.out <- nimbleMCMC(code = myCode, data = myData, inits = myInits,
                       monitors = c("intercept", "beta","sigma"), 
                       thin = 10,
                       niter = 10000, nburnin=1000,
                       nchains = 1, setSeed = FALSE,
                       constants = myConstants,samplesAsCodaMCMC=TRUE)
```


```{r}
summary(mcmc.out)
```
From R's lm above:
intercept = 5.794e-17 (~ 0)
weight = 7.547e-01
sigma = 0.6569515

```{r}
library(coda)
traceplot(mcmc.out)
densplot(mcmc.out)
```


6) We fit the linear model using the rstan package in R, which is an interface 
to Stan (outside of R). Report the parameter estimates for the intercept, effect
of height, and sigma. Are they the same as from ‘lm’? 


```{r}
library("rstan")
# options(mc.cores = parallel::detectCores())
# rstan_options(auto_write = TRUE)

kung_dat <- list(N=dim(d3)[1],weight = d3$weight,height = d3$height)

fit <- stan(file = 'lm.stan', data = kung_dat,
            iter=10000, warmup=2500,thin=10,chains=4)

print(fit,pars=c('intercept','beta','sigma'),digits_summary = 3,
      probs = c(0.025,0.5,0.975))

```
           mean se_mean    sd   2.5%   50% 97.5% n_eff  Rhat
intercept 0.000   0.001 0.036 -0.071 0.001 0.073  2916 0.999
beta      0.755   0.001 0.035  0.689 0.755 0.824  2791 1.000
sigma     0.659   0.000 0.025  0.612 0.658 0.710  2974 0.999

compared to R's lm above:
intercept = 5.794e-17 (~ 0)
weight = 7.547e-01
sigma = 0.6569515

```{r}
plot(fit)


```

